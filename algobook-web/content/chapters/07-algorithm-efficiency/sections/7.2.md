# Measuring Performance: Timing and Counting Operations

In Section 7.1, you experienced the shocking reality that algorithm choice can mean the difference between milliseconds and hours. You saw linear search struggling with large datasets while binary search handled them effortlessly. 

**But here's the question every programmer faces**: How do you measure these differences systematically? How do you predict which algorithm will be faster before your users experience the pain of a slow application?

The answer lies in learning to measure algorithm performance like a detective gathering evidence. You'll use two powerful techniques: **timing** (measuring real-world performance) and **operation counting** (measuring algorithmic work). Together, these tools will transform you from someone who hopes their code is fast into someone who *knows* their code is fast.

## Learning Objectives

By the end of this section, you will:
- Use Python's `time` module to measure execution time
- Count fundamental operations in algorithms
- Conduct systematic performance experiments
- Understand the relationship between input size and runtime
- Apply profiling techniques to analyze code performance

## Python's Time Module

Let's start with the most intuitive approach: **timing how long your code actually takes to run.** This is what users experience—when they click a button, how long do they wait for results?

Python's `time` module makes this surprisingly simple. The basic idea is like using a stopwatch: record the time when you start, record the time when you finish, then calculate the difference.

```python-execute
import time

def simple_timing_example():
    # Record start time
    start_time = time.time()
    
    # Do some work
    total = 0
    for i in range(1000000):
        total += i
    
    # Record end time
    end_time = time.time()
    
    # Calculate elapsed time
    elapsed_time = end_time - start_time
    print(f"Calculation took {elapsed_time:.4f} seconds")
    print(f"Result: {total}")

simple_timing_example()
```

```note title="Understanding time.time()"
`time.time()` returns the current time as a floating-point number of seconds since January 1, 1970. By subtracting start from end time, we get the elapsed duration in seconds.
```

Let's create a more robust timing function:

```python-execute
import time

def time_function(func, *args, **kwargs):
    """Time a function call and return the result and elapsed time"""
    start_time = time.time()
    result = func(*args, **kwargs)
    end_time = time.time()
    elapsed_time = end_time - start_time
    return result, elapsed_time

# Example: Time different summation methods
def sum_with_loop(n):
    total = 0
    for i in range(1, n + 1):
        total += i
    return total

def sum_with_formula(n):
    return n * (n + 1) // 2

def sum_with_builtin(n):
    return sum(range(1, n + 1))

# Test each method
n = 1000000
result1, time1 = time_function(sum_with_loop, n)
result2, time2 = time_function(sum_with_formula, n)
result3, time3 = time_function(sum_with_builtin, n)

print(f"Loop method:     {time1:.4f} seconds, result: {result1}")
print(f"Formula method:  {time2:.4f} seconds, result: {result2}")
print(f"Built-in method: {time3:.4f} seconds, result: {result3}")
```

```hint title="Multiple Runs for Accuracy"
Timing can vary due to system load and other factors. Professional performance testing runs algorithms multiple times and averages the results for more accurate measurements.
```

You can see the power of timing—it reveals that mathematical formulas can be dramatically faster than loops for the same calculation. **But timing has a limitation**: it depends on your specific computer, the current system load, and even the temperature of your CPU.

What if you want to understand the *inherent* efficiency of an algorithm, independent of hardware? What if you want to predict how an algorithm will perform on a faster computer or a slower mobile device?

## Counting Operations

This is where operation counting becomes invaluable. **Instead of measuring time, we count the fundamental work the algorithm performs.** Think of it as counting the "effort" required, regardless of how fast or slow the computer executing that effort happens to be.

Let's see this in action, but first, **you'll practice adding operation counting yourself**:

**Key insight**: Adding operation counting is straightforward—just increment a counter before each fundamental operation (comparison). This lets you measure algorithmic work independent of hardware speed.

```quiz
id: operation-counting
question: What is the main advantage of counting operations versus timing algorithms?
options:
  - id: a
    text: Counting is always more accurate than timing
    correct: false
    explanation: Both have their place. Timing shows real performance, while counting shows algorithmic behavior.
  - id: b
    text: Operation counts are independent of hardware and system load
    correct: true
    explanation: Correct! Operation counts reveal the inherent algorithmic complexity, while timing can vary based on hardware and system conditions.
  - id: c
    text: Counting is easier to implement
    correct: false
    explanation: Actually, adding counters can make code more complex, but it provides valuable insights.
  - id: d
    text: Counting works better for small datasets
    correct: false
    explanation: Both timing and counting work for any dataset size, but they measure different aspects.
```

### Discovery Exercise: Algorithm Detective

Before we dive into systematic analysis, let's play algorithm detective. Below are three mystery algorithms that count their operations. **Your mission**: Test them with different input sizes and see if you can guess their performance patterns!

```python-execute
def mystery_algorithm_alpha(n):
    """Can you guess what this algorithm's complexity is?"""
    operations = 0
    for i in range(n):
        operations += 1
    return operations

def mystery_algorithm_beta(n):
    """This one has a different pattern..."""
    operations = 0
    for i in range(n):
        for j in range(n):
            operations += 1
    return operations

def mystery_algorithm_gamma(n):
    """And this one is interesting too!"""
    operations = 0
    while n > 1:
        operations += 1
        n = n // 2
    return operations

# Test them yourself! Try different values of n
print("Testing Mystery Algorithms:")
for size in [10, 20, 40, 80]:
    alpha_ops = mystery_algorithm_alpha(size)
    beta_ops = mystery_algorithm_beta(size)
    gamma_ops = mystery_algorithm_gamma(size)
    
    print(f"Input {size:2}: Alpha={alpha_ops:4}, Beta={beta_ops:5}, Gamma={gamma_ops:2}")

print("\nCan you see the patterns? Which grows fastest as input size doubles?")
```

```hint title="Pattern Detective Tips"
- **Alpha**: Notice how operations change when input doubles (10→20, 20→40, 40→80)
- **Beta**: This one grows much faster! How many times larger when input doubles?
- **Gamma**: This one barely grows at all. What's happening here?
```

## Systematic Performance Analysis

Did you spot the patterns in the mystery algorithms? If you guessed that Alpha grows linearly (operations = input size), Beta grows quadratically (operations = input size squared), and Gamma grows logarithmically (operations barely increase), you're developing algorithmic intuition!

Now let's apply this detective work to real algorithms. **The key insight**: by testing algorithms with systematically increasing input sizes, we can discover their performance patterns and predict how they'll behave with even larger datasets.

```python-execute
import time
import random

def performance_experiment():
    """Systematic performance analysis of different algorithms"""
    
    def linear_search_with_count(data, target):
        """Linear search that counts operations"""
        comparisons = 0
        for i, value in enumerate(data):
            comparisons += 1  # Count each comparison
            if value == target:
                return i, comparisons
        return -1, comparisons

    def binary_search_with_count(data, target):
        """Binary search that counts operations (assumes sorted data)"""
        comparisons = 0
        left, right = 0, len(data) - 1
        
        while left <= right:
            comparisons += 1  # Count each comparison
            mid = (left + right) // 2
            if data[mid] == target:
                return mid, comparisons
            elif data[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        return -1, comparisons
    
    # Test different input sizes
    sizes = [10, 100, 1000, 10000, 100000]
    
    print("Performance Analysis: Linear vs Binary Search")
    print("Size     | Linear (ms) | Binary (ms) | Linear Ops | Binary Ops")
    print("-" * 65)
    
    for size in sizes:
        # Create test data
        data = list(range(size))
        target = random.randint(size//4, 3*size//4)  # Target in middle range
        
        # Time linear search
        start = time.time()
        linear_result, linear_ops = linear_search_with_count(data, target)
        linear_time = (time.time() - start) * 1000  # Convert to milliseconds
        
        # Time binary search  
        start = time.time()
        binary_result, binary_ops = binary_search_with_count(data, target)
        binary_time = (time.time() - start) * 1000
        
        print(f"{size:4} | {linear_time:9.3f} | {binary_time:9.3f} | {linear_ops:8} | {binary_ops:8}")

performance_experiment()
```

## Understanding Performance Patterns

Let's visualize how performance scales with different input sizes:

```python-execute
def analyze_growth_patterns():
    """Analyze how different algorithms scale with input size"""
    
    sizes = [10, 50, 100, 500, 1000, 5000]
    
    print("Growth Pattern Analysis")
    print("Size   | Linear | Quadratic | Logarithmic | Constant")
    print("-" * 55)
    
    for size in sizes:
        linear_ops = size                    # O(n)
        quadratic_ops = size * size          # O(n²)
        logarithmic_ops = int(size.bit_length())  # Approximation of log₂(n)
        constant_ops = 1                     # O(1)
        
        print(f"{size:4} | {linear_ops:6} | {quadratic_ops:9} | {logarithmic_ops:11} | {constant_ops:8}")

analyze_growth_patterns()
```

```warning title="Quadratic Growth Warning"
Notice how quadratic operations (O(n²)) explode as input size grows! This is why nested loops can be dangerous for large datasets. An algorithm that's fine for 100 items might be unusable for 5000 items.
```

## Advanced Timing Techniques

For more precise measurements, Python provides additional timing tools:

```python-execute
import timeit

def advanced_timing_example():
    """Demonstrate more precise timing techniques"""
    
    # Using timeit for more accurate measurements
    setup_code = "data = list(range(1000)); target = 500"
    
    linear_code = """
for i, value in enumerate(data):
    if value == target:
        break
"""
    
    binary_code = """
left, right = 0, len(data) - 1
while left <= right:
    mid = (left + right) // 2
    if data[mid] == target:
        break
    elif data[mid] < target:
        left = mid + 1
    else:
        right = mid - 1
"""
    
    # Run each test multiple times for accuracy
    linear_time = timeit.timeit(linear_code, setup_code, number=10000)
    binary_time = timeit.timeit(binary_code, setup_code, number=10000)
    
    print("Precise timing with timeit (10,000 runs each):")
    print(f"Linear search:  {linear_time:.6f} seconds total, {linear_time/10000*1000:.6f} ms average")
    print(f"Binary search:  {binary_time:.6f} seconds total, {binary_time/10000*1000:.6f} ms average")
    print(f"Speed difference: {linear_time/binary_time:.1f}x")

advanced_timing_example()
```

## Memory Usage Analysis

Performance isn't just about time - memory usage matters too:

```python-execute
import sys

def memory_analysis():
    """Analyze memory usage of different data structures"""
    
    # List vs generator comparison
    size = 10000
    
    # Memory-intensive: Store all values
    memory_list = [x*x for x in range(size)]
    list_memory = sys.getsizeof(memory_list)
    
    # Memory-efficient: Generate values on demand
    memory_generator = (x*x for x in range(size))
    generator_memory = sys.getsizeof(memory_generator)
    
    print("Memory Usage Analysis:")
    print(f"List (stores all {size} values):      {list_memory:,} bytes")
    print(f"Generator (computes on demand):       {generator_memory:,} bytes")
    print(f"Memory savings: {list_memory/generator_memory:.1f}x less memory")
    
    # Show that generators still work
    generator_sum = sum(x*x for x in range(10))
    list_sum = sum([x*x for x in range(10)])
    print(f"Both produce same result: {generator_sum} = {list_sum}")

memory_analysis()
```

```note title="Time vs Space Tradeoffs"
Often there's a tradeoff between time and space. Generators use less memory but might compute values multiple times. Lists use more memory but provide instant access. Understanding these tradeoffs helps you choose the right approach.
```

## Practical Profiling

Let's put it all together with a comprehensive performance comparison:

```python-execute
import time

def comprehensive_performance_test():
    """Comprehensive test comparing multiple algorithms"""
    
    algorithms = {
        "Bubble Sort": lambda arr: bubble_sort_timed(arr.copy()),
        "Selection Sort": lambda arr: selection_sort_timed(arr.copy()), 
        "Python Sort": lambda arr: python_sort_timed(arr.copy())
    }
    
    sizes = [10, 50, 100, 500, 1000]
    
    print("Comprehensive Algorithm Performance Comparison")
    print("=" * 70)
    
    for size in sizes:
        print(f"\nTesting with {size} random numbers:")
        test_data = list(range(size, 0, -1))  # Worst case: reverse order
        
        for name, algorithm in algorithms.items():
            start_time = time.time()
            sorted_data, operations = algorithm(test_data)
            end_time = time.time()
            
            elapsed = (end_time - start_time) * 1000  # milliseconds
            print(f"  {name:12}: {elapsed:7.2f} ms, {operations:,} operations")

def bubble_sort_timed(arr):
    operations = 0
    n = len(arr)
    for i in range(n):
        for j in range(0, n-i-1):
            operations += 1
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
    return arr, operations

def selection_sort_timed(arr):
    operations = 0
    for i in range(len(arr)):
        min_idx = i
        for j in range(i+1, len(arr)):
            operations += 1
            if arr[j] < arr[min_idx]:
                min_idx = j
        arr[i], arr[min_idx] = arr[min_idx], arr[i]
    return arr, operations

def python_sort_timed(arr):
    # Python's sort is highly optimized, estimating operations
    operations = len(arr) * 15  # Rough estimate for comparison
    arr.sort()
    return arr, operations

comprehensive_performance_test()
```

```exercise
id: operation-counting-exercise
title: Add Operation Counting to Search Algorithms
description: |
  Add operation counting to the provided search algorithms. Focus on counting comparison operations 
  to measure algorithmic efficiency. Your task is to add `operations += 1` statements before each 
  comparison operation.
difficulty: medium
prepend: |
  # Parse input and set up test cases - students don't see this
  sizes_and_targets = input().strip().split()
  test_cases = []
  
  for i in range(0, len(sizes_and_targets), 2):
      size = int(sizes_and_targets[i])
      target = int(sizes_and_targets[i + 1])
      data = list(range(size))
      test_cases.append((data, target))
starterCode: |
  def linear_search_counter(data, target):
      """Linear search that counts and returns operations performed"""
      operations = 0
      for i, value in enumerate(data):
          # TODO: Add operation counting here (before the comparison)
          if value == target:
              return i, operations
      return -1, operations
  
  def binary_search_counter(data, target):
      """Binary search that counts and returns operations performed"""  
      operations = 0
      left, right = 0, len(data) - 1
      
      while left <= right:
          # TODO: Add operation counting here (before the comparison)
          mid = (left + right) // 2
          if data[mid] == target:
              return mid, operations
          elif data[mid] < target:
              left = mid + 1
          else:
              right = mid - 1
      
      return -1, operations
postpend: |
  # Run tests and display results - students don't see this
  
  print("Operation Counting Results:")
  print("Size     | Linear Ops | Binary Ops | Efficiency Ratio")
  print("-" * 50)
  
  for data, target in test_cases:
      linear_index, linear_ops = linear_search_counter(data, target)
      binary_index, binary_ops = binary_search_counter(data, target)
      
      if binary_ops > 0:
          ratio = linear_ops / binary_ops
          print(f"{len(data):4} | {linear_ops:8} | {binary_ops:8} | {ratio:11.1f}x")
      else:
          print(f"{len(data):4} | {linear_ops:8} | {binary_ops:8} | {'N/A':>11}")
testCases:
  - input: "10 7 100 75 1000 500 10000 7500"
    expectedOutput: "Operation Counting Results:\nSize     | Linear Ops | Binary Ops | Efficiency Ratio\n--------------------------------------------------\n  10 |        8 |        2 |         4.0x\n 100 |       76 |        6 |        12.7x\n1000 |      501 |        9 |        55.7x\n10000 |     7501 |       13 |       577.0x"
hints:
  - "Add 'operations += 1' before each comparison operation (==, <, >, etc.)"
  - "In linear search, count before checking 'if value == target'"
  - "In binary search, count before checking 'if data[mid] == target'"
  - "The test cases and output formatting are already handled for you"
solution: |
  def linear_search_counter(data, target):
      """Linear search that counts and returns operations performed"""
      operations = 0
      for i, value in enumerate(data):
          operations += 1  # Count the comparison
          if value == target:
              return i, operations
      return -1, operations
  
  def binary_search_counter(data, target):
      """Binary search that counts and returns operations performed"""  
      operations = 0
      left, right = 0, len(data) - 1
      
      while left <= right:
          operations += 1  # Count the comparison
          mid = (left + right) // 2
          if data[mid] == target:
              return mid, operations
          elif data[mid] < target:
              left = mid + 1
          else:
              right = mid - 1
      
      return -1, operations
```

## Key Takeaways

- **Timing reveals real-world performance**: Use `time.time()` and `timeit` for accurate measurements
- **Operation counting shows algorithmic behavior**: Independent of hardware, shows inherent complexity
- **Systematic testing is crucial**: Test multiple input sizes to understand scaling behavior
- **Multiple measurement approaches**: Combine timing, operation counting, and memory analysis
- **Hardware matters for timing**: Operation counts are more predictable across different systems
- **Professional profiling**: Use proper statistical methods (multiple runs, averages) for accuracy

You've now learned to be an algorithm performance detective! You can time real-world performance, count algorithmic operations, and systematically analyze how algorithms scale with input size. You've even discovered patterns in mystery algorithms.

**But here's the next level question**: What if you could predict an algorithm's performance pattern just by looking at the code, without running any experiments at all? What if you could classify algorithms into categories (linear, quadratic, logarithmic) using mathematical analysis?

This is exactly what the next section teaches. You'll learn Big O notation—the mathematical language that computer scientists use to describe and predict algorithm efficiency. It's like having a crystal ball for code performance!

```quiz
id: measurement-techniques
question: You want to compare two algorithms that will run on different computers. Which measurement technique gives the most consistent results across different hardware?
options:
  - id: a
    text: Timing with time.time()
    correct: false
    explanation: Timing varies significantly across different hardware and system loads.
  - id: b
    text: Counting fundamental operations
    correct: true
    explanation: Correct! Operation counts reveal algorithmic complexity independent of hardware speed or system conditions.
  - id: c
    text: Measuring memory usage
    correct: false
    explanation: While useful, memory usage doesn't directly indicate algorithmic efficiency across different systems.
  - id: d
    text: Using timeit module
    correct: false
    explanation: While timeit is more accurate than basic timing, it still varies across different hardware.
```